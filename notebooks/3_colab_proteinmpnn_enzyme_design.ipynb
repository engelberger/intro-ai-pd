{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engelberger/intro-ai-pd/blob/master/notebooks/3_colab_proteinmpnn_enzyme_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IVmFMidn965N"
      },
      "source": [
        "# AI based protein design UDLA 2023 \n",
        "## **Using ProteinMPNN to design plastic degrading enzymes**\n",
        "#### **Base notebook Authors:**\n",
        "- **[Sergey Ovchinnikov](https://www.solab.org/)**\n",
        "- **[Simon Kozlov](https://twitter.com/sim0nsays?lang=en)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "fixbb monomer design:\n",
        " - `pdb=\"6MRR\" chains=\"A\"`\n",
        "\n",
        "fixbb homooligomer design:\n",
        " - `pdb=\"5XZK\" chains=\"A,B,C\" homooligomer=True`\n",
        "\n",
        "binder design:\n",
        " - `pdb=\"1SSC\" chains=\"A,B\" fix_pos=\"A\"`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tnwjNa-IWMSA"
      },
      "outputs": [],
      "source": [
        "#@title Install colabdesign\n",
        "import os\n",
        "try:\n",
        "  import colabdesign\n",
        "except:\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@v1.1.1\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.7/dist-packages/colabdesign colabdesign\")\n",
        "\n",
        "from colabdesign.mpnn import mk_mpnn_model, clear_mem\n",
        "from colabdesign.shared.protein import pdb_to_string\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import tqdm.notebook\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "def get_pdb(pdb_code=\"\"):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  elif os.path.isfile(pdb_code):\n",
        "    return pdb_code\n",
        "  elif len(pdb_code) == 4:\n",
        "    os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
        "    return f\"{pdb_code}.pdb\"\n",
        "  else:\n",
        "    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v3.pdb\")\n",
        "    return f\"AF-{pdb_code}-F1-model_v3.pdb\"\n",
        "\n",
        "\n",
        "# First, update the package list and install necessary packages\n",
        "!sudo apt-get update && sudo apt-get install -y wget curl ncbi-blast+\n",
        "\n",
        "# Since Google Colab is based on Ubuntu, we can download and install the MAFFT package directly\n",
        "# Define the version number as a variable for easier updates\n",
        "mafft_version = \"7.475\"\n",
        "\n",
        "# Download and install MAFFT\n",
        "!wget https://mafft.cbrc.jp/alignment/software/mafft_{mafft_version}-1_amd64.deb\n",
        "!sudo dpkg -i mafft_{mafft_version}-1_amd64.deb\n",
        "!rm mafft_{mafft_version}-1_amd64.deb\n",
        "\n",
        "# Install specific Python packages\n",
        "!pip install --quiet 'colabfold[alphafold-minus-jax]@git+https://github.com/sokrypton/ColabFold'\n",
        "!pip install --upgrade dm-haiku\n",
        "!pip install git+https://github.com/jonathanking/BioPython-A3MIO\n",
        "\n",
        "# Create a data directory (if needed)\n",
        "!mkdir -p /content/data\n",
        "\n",
        "\n",
        "from os.path import exists\n",
        "\"\"\"\n",
        "This script was obtained from ProteinMPNN helper scripts/other tools. However, additional modifications had to be made to\n",
        "fit this particular tool\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "def softmax(x, T):\n",
        "    return np.exp(x/T)/np.sum(np.exp(x/T), -1, keepdims=True)\n",
        "\n",
        "def parse_pssm(path, seq_len):\n",
        "    data = pd.read_csv(path, skiprows=2)\n",
        "    floats_list_list = []\n",
        "    for i in range(seq_len):\n",
        "        str1 = data.values[i][0][8:]\n",
        "        floats_list = []\n",
        "        for item in str1.split():\n",
        "            floats_list.append(float(item))\n",
        "        floats_list_list.append(floats_list)\n",
        "    np_lines = np.array(floats_list_list)\n",
        "    return np_lines\n",
        "\n",
        "\n",
        "def make_dict(seq_len):\n",
        "    np_lines = parse_pssm('.temp/pssm.txt', seq_len)\n",
        "\n",
        "    mpnn_alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    input_alphabet = 'ARNDCQEGHILKMFPSTWYV'\n",
        "\n",
        "    permutation_matrix = np.zeros([20,21])\n",
        "    for i in range(20):\n",
        "        letter1 = input_alphabet[i]\n",
        "        for j in range(21):\n",
        "            letter2 = mpnn_alphabet[j]\n",
        "            if letter1 == letter2:\n",
        "                permutation_matrix[i,j]=1.\n",
        "\n",
        "    pssm_log_odds = np_lines[:,:20] @ permutation_matrix\n",
        "    pssm_probs = np_lines[:,20:40] @ permutation_matrix\n",
        "\n",
        "    X_mask = np.concatenate([np.zeros([1,20]), np.ones([1,1])], -1)\n",
        "\n",
        "    def softmax(x, T):\n",
        "        return np.exp(x/T)/np.sum(np.exp(x/T), -1, keepdims=True)\n",
        "\n",
        "    #Load parsed PDBs:  \n",
        "    with open('.temp/parsed_pdbs.jsonl', 'r') as json_file:\n",
        "        json_list = list(json_file)\n",
        "\n",
        "    my_dict = {}\n",
        "    for json_str in json_list:\n",
        "        result = json.loads(json_str)\n",
        "        all_chain_list = [item[-1:] for item in list(result) if item[:9]=='seq_chain']\n",
        "        pssm_dict = {}\n",
        "        for chain in all_chain_list:\n",
        "            pssm_dict[chain] = {}\n",
        "            pssm_dict[chain]['pssm_coef'] = (np.ones(len(result['seq_chain_A']))).tolist() #a number between 0.0 and 1.0 specifying how much attention put to PSSM, can be adjusted later as a flag\n",
        "            pssm_dict[chain]['pssm_bias'] = (softmax(pssm_log_odds-X_mask*1e8, 1.0)).tolist() #PSSM like, [length, 21] such that sum over the last dimension adds up to 1.0\n",
        "            pssm_dict[chain]['pssm_log_odds'] = (pssm_log_odds).tolist()\n",
        "        my_dict[result['name']] = pssm_dict\n",
        "\n",
        "    #Write output to:    \n",
        "    with open('.temp/pssm_dict.jsonl', 'w') as f:\n",
        "        f.write(json.dumps(my_dict) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "from colabfold.colabfold import run_mmseqs2\n",
        "from Bio import SeqIO, AlignIO\n",
        "from colabdesign.mpnn import mk_mpnn_model\n",
        "from colabdesign.mpnn.model import aa_order\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "import json\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import time\n",
        "import shutil\n",
        "import requests\n",
        "from io import StringIO\n",
        "from collections import defaultdict\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "#import make_pssm_dict as prep_mpnn\n",
        "\n",
        "import requests\n",
        "import time\n",
        "\n",
        "class evoFilter():\n",
        "    \n",
        "    def __init__(self, pdb_id: str):\n",
        "        self.name = pdb_id.lower() \n",
        "        self.native = \"\"\n",
        "        self.seq_len = 0\n",
        "        \n",
        "        \n",
        "    def run(self):\n",
        "            \n",
        "        print(\"Creating temporary directories...\")\n",
        "        # create a temp file for this tool that will be deleted later\n",
        "        os.makedirs(f\"{self.name}\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.name}/results\", exist_ok=True)\n",
        "        os.makedirs(\".temp\", exist_ok=True) \n",
        "        \n",
        "        \n",
        "        # get fastas from rcsb database\n",
        "        # self.get_fasta(self.name, f\"example_run/{self.name}.fasta\")\n",
        "        # run fastas on colabfold alphafold2_batch googlecolab and place folded pdbs in example_run\n",
        "        \n",
        "        # update native sequence and length\n",
        "        print(\"Reading fasta file...\")\n",
        "        os.makedirs(f\"benchmarked\", exist_ok=True)\n",
        "        # Download from the link\n",
        "        url = f\"https://raw.githubusercontent.com/engelberger/intro-ai-pd/master/fasta/6ane.fasta\"\n",
        "        os.system(f\"wget {url} -O benchmarked/6ane.fasta\")\n",
        "        url2 = f\"https://raw.githubusercontent.com/engelberger/intro-ai-pd/master/pdbs/6ane_A.pdb\"\n",
        "        os.system(f\"wget {url2} -O benchmarked/6ane.pdb\")\n",
        "        \n",
        "        with open(f\"benchmarked/{self.name}.fasta\", \"r\") as fasta:\n",
        "            self.native = fasta.readlines()[-1].replace(\"\\n\",\"\")\n",
        "            self.seq_len = len(self.native)\n",
        "\n",
        "        # run sequence alignment using colabdesign api\n",
        "        # at the moment the goal here is to retrieve a sequence alignment file\n",
        "        # which later is trasnformed into a multifasta file which\n",
        "        # later is transformed into a fasta alignment file\n",
        "        # that will be used to make a pssm matrix using psiblast\n",
        "        print(\"Running MMSEQS2 to get related evolutionary sequences...\")\n",
        "        run_mmseqs2(self.native, self.name)\n",
        "\n",
        "        # TODO : Implement a redundancy check with HHblits \n",
        "        # similar to the one in predict.ipynb by sergey in ColabDesign\n",
        "        \n",
        "        # find and parse a3m file to write to string\n",
        "        print(\"Parsing a3m file...\")\n",
        "        seq_str = ''\n",
        "        records = SeqIO.parse(f\"{self.name}_env/uniref.a3m\", \"fasta\")\n",
        "\n",
        "        for record in records:\n",
        "            seq_str += (\">\" + str(record.id) + '\\n')\n",
        "            seq_str += (str(record.seq).replace(\"-\",\"\") + '\\n')\n",
        "\n",
        "        #run ClustalO on mmseq2 sequences\n",
        "        print(\"Running ClustalO for sequence alignment...\")\n",
        "        child = subprocess.Popen(['mafft', '--quiet', '-'], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
        "        child.stdin.write(seq_str.encode())\n",
        "        child_out = child.communicate()[0].decode('utf8')\n",
        "        alignment = AlignIO.read(StringIO(child_out), 'fasta')\n",
        "        child.stdin.close()\n",
        "\n",
        "        # take aligned target sequence, and get all positions with gaps\n",
        "        # remove these gap positions from other sequences\n",
        "        print(\"Processing sequence alignment results...\")\n",
        "        reference = alignment[0].seq\n",
        "        to_del = []\n",
        "        for i in range(len(reference)):\n",
        "            if reference[i] == \"-\":\n",
        "                to_del.append(i)\n",
        "                \n",
        "        for align in alignment:\n",
        "            pos = {}\n",
        "            for i in range(len(align.seq)):\n",
        "                pos[i] = align.seq[i]\n",
        "            for key in to_del:\n",
        "                pos.pop(key)\n",
        "            align.seq = \"\".join(list(pos.values()))\n",
        "        \n",
        "        \n",
        "        # run MPNN and update json database\n",
        "        print(\"Running Blast...\")\n",
        "        os.makedirs(\"temp\",  exist_ok=True)\n",
        "        status_one = self.get_pssm(alignment=alignment)\n",
        "        #print(\"MPNN status: \", status_one)\n",
        "        #status_two = self.run_mpnn()\n",
        "        #print(\"MPNN status: \", status_two)\n",
        "#\n",
        "        ## obtain top 10 mutations\n",
        "        #print(\"Getting top 10 mutations...\")\n",
        "        #data = self.get_muts()\n",
        "        #data.to_csv(f\"{self.name}/results/{self.name}.csv\", index=False)\n",
        "        #\n",
        "        #print(\"Writing sequences to JSON file...\")\n",
        "        #with open(f\"{self.name}/results/{self.name}_sequences.json\", \"w\") as f:\n",
        "        #    json.dump(self.get_seqs(data), f)\n",
        "        #\n",
        "        ## delete temp folder and MSA folder\n",
        "        #print(\"Cleaning up temporary files...\")\n",
        "        #shutil.rmtree(\"./.temp\")\n",
        "        #shutil.rmtree(f\"./{self.name}_env\")\n",
        "\n",
        "        return alignment\n",
        "\n",
        "    # TODO: get fasta from user given pdb file\n",
        "    def get_fasta(self, pdb_id, output_file):\n",
        "        url = f\"https://www.rcsb.org/fasta/entry/{pdb_id}\"\n",
        "        \n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an exception for any HTTP error\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to retrieve FASTA for PDB ID {pdb_id}: {e}\")\n",
        "            return\n",
        "        \n",
        "        fasta_text = response.text.strip()\n",
        "        if fasta_text:\n",
        "            with open(output_file, \"w\") as f:\n",
        "                f.write(fasta_text)\n",
        "        else:\n",
        "            print(f\"No FASTA data found for PDB ID {pdb_id}\")\n",
        "            \n",
        "\n",
        "    def get_fasta_retry(self, pdb_id, output_file, max_retries=5):\n",
        "        url = f\"{self.base_url}{pdb_id}\"\n",
        "        retry_count = 0\n",
        "        wait_time = 1  # initial wait time in seconds, you could adjust as needed\n",
        "\n",
        "        while retry_count < max_retries:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                response.raise_for_status()\n",
        "                fasta_text = response.text.strip()\n",
        "                \n",
        "                if fasta_text:\n",
        "                    with open(output_file, \"w\") as f:\n",
        "                        f.write(fasta_text)\n",
        "                    print(f\"FASTA data for PDB ID {pdb_id} saved to {output_file}\")\n",
        "                    return\n",
        "                else:\n",
        "                    print(f\"No FASTA data found for PDB ID {pdb_id}\")\n",
        "                    return\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Attempt {retry_count + 1}: Failed to retrieve FASTA for PDB ID {pdb_id}. Error: {e}\")\n",
        "                retry_count += 1\n",
        "                time.sleep(wait_time)\n",
        "                wait_time *= 2  # double the wait time for the next retry\n",
        "        print(\"Max retries reached. Failed to retrieve FASTA data.\")\n",
        "        \n",
        "    def get_pssm(self, alignment):\n",
        "        \"\"\"Get a PSSM matrix by running psi blast against MSA object; process it for MPNN\"\"\"\n",
        "        \n",
        "        # Write MSA to FASTA file and turn it into a database\n",
        "        db = f\".temp/database.fasta\"\n",
        "        seq_records = [SeqIO.SeqRecord(seq=record.seq, id=record.id, description=\"\") for record in alignment]\n",
        "        tmp = open(db, 'w')\n",
        "        for records in seq_records:\n",
        "            tmp.write(\">\" + records.id + \"\\n\")\n",
        "            tmp.write(records.seq + \"\\n\")\n",
        "        tmp.close()\n",
        "        subprocess.run(\"makeblastdb -in .temp/database.fasta -dbtype prot -out .temp/db\", shell=True)\n",
        "\n",
        "        # prepare for psi blast pssm\n",
        "        query = f\"benchmarked/{self.name}.fasta\"\n",
        "\n",
        "        # obtain a PSSM matrix using psi blast\n",
        "        subprocess.run(f'psiblast -query {query} -db .temp/db -num_iterations 3 -out_ascii_pssm \\\n",
        "                       ./temp/pssm.txt -outfmt 0', shell=True)\n",
        "        \n",
        "        return \"PSSM matrix has been successfully produced and saved in temp/pssm.txt\"\n",
        "\n",
        "    def _task(self, i):\n",
        "        # multithreaded process of runing MPNN\n",
        "        \n",
        "        pos_data = defaultdict(list)\n",
        "        \n",
        "        # get PSSM matrix\n",
        "        with open('.temp/pssm_dict.jsonl','r') as pssm:\n",
        "            temp = json.load(pssm)\n",
        "            bias = temp[self.name][\"A\"][\"pssm_bias\"]\n",
        "            \n",
        "        bias_matrix = bias[i]\n",
        "        pos = i + 1\n",
        "        \n",
        "        if i < 1:\n",
        "            fixed = f\"{pos+1}-{len(bias)}\"\n",
        "        elif pos >= len(bias):\n",
        "            fixed = f\"1-{i}\"\n",
        "        elif i == 1:\n",
        "            fixed = f\"1, {pos+1}-{len(bias)}\"\n",
        "        elif ((pos+1) == len(bias)):\n",
        "            fixed = f\"1-{i},{len(bias)}\"\n",
        "        else:\n",
        "            fixed = f\"1-{i},{pos+1}-{len(bias)}\"\n",
        "            \n",
        "        # create mpnn model\n",
        "        mpnn_model = mk_mpnn_model()\n",
        "        print(f\"Processing {self.name}/{self.name}.pdb\")\n",
        "        mpnn_model.prep_inputs(pdb_filename=f\"{self.name}/{self.name}.pdb\", \n",
        "                            fix_pos=fixed,\n",
        "                            chain=\"A\",)\n",
        "        \n",
        "        # adjust PSSM probabilities\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "        for aa in range(len(alphabet)):\n",
        "            mpnn_model._inputs[\"bias\"][i,aa_order[alphabet[aa]]] = bias_matrix[aa]\n",
        "        \n",
        "        samples = mpnn_model.sample_parallel(batch=5)\n",
        "        \n",
        "        # record the data\n",
        "        ctr = 0\n",
        "        for sequence in samples[\"seq\"]:\n",
        "            for j in range(self.seq_len):\n",
        "                if self.native[j] != sequence[j]:\n",
        "                    pos_data[\"sequence\"].append(sequence)\n",
        "                    mut = f\"{self.native[j]}    {sequence[j]}\" # record what native position has been mutated to\n",
        "                    pos_data[\"mutation\"].append(mut) \n",
        "                    pos_data[\"score\"].append(samples[\"score\"][ctr])\n",
        "            ctr += 1   \n",
        "        \n",
        "        if pos_data:\n",
        "            df = pd.DataFrame(pos_data)\n",
        "            df['score'] = pd.to_numeric(df['score'])\n",
        "            df2 = df.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
        "            df3 = df2.head(1)\n",
        "            df3.to_csv(f\".temp/csv/{self.name}_{i}.csv\", index=False, header=False)\n",
        "        \n",
        "        return \"One position has been designed, and the amino acid mutation that led \\\n",
        "            to the greatest improvement in thermostability has been recorded.\"\n",
        "\n",
        "    def run_mpnn(self):\n",
        "        \"\"\"\n",
        "        Run helper scripts and protein MPNN\n",
        "        \"\"\"\n",
        "        \n",
        "        os.makedirs(f\"./temp/csv\", exist_ok=True)\n",
        "\n",
        "        # Run helper scripts to set up for MPNN\n",
        "        subprocess.run(f\"python ProteinMPNN/helper_scripts/parse_multiple_chains.py \\\n",
        "                        --input_path {self.name} \\\n",
        "                        --output_path .temp/parsed_pdbs.jsonl\", shell=True)\n",
        "        \n",
        "        prep_mpnn.make_dict(self.seq_len)\n",
        "        \n",
        "        start = time.time()\n",
        "\n",
        "        # Run MPNN on sequence and mutating +_scoring one by one\n",
        "        print(\"Mutating positions one by one...\")\n",
        "        # Set the maximum number of threads to 1 \n",
        "        # to avoid overloading the laptop,\n",
        "        # should be modified in production\n",
        "        pool = ThreadPool(1)\n",
        "        pool.map(self._task, range(self.seq_len))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        \n",
        "        end = time.time()\n",
        "        \n",
        "        return f\"MPNN has finished running in {end-start} seconds, and all data has been recorded in .temp/csv.\"\n",
        "   \n",
        "    def get_muts(self):\n",
        "        \n",
        "        all_data = {\n",
        "            \"Position\": [],\n",
        "            \"Sequence\": [],\n",
        "            \"Wildtype\": [],\n",
        "            \"Mutant\": [],\n",
        "            \"Score\": []\n",
        "        }\n",
        "        \n",
        "        # iterate through the csv directory\n",
        "        filenames = listdir(f\".temp/csv\")\n",
        "        files = [filename for filename in filenames if filename.endswith(\".csv\")]\n",
        "        \n",
        "        for file in files:\n",
        "            all_data[\"Position\"].append(int(file.replace(\".csv\",\"\").split(\"_\")[-1]) + 1)\n",
        "            with open(os.path.join(f\".temp/csv\", file), \"r\") as f:\n",
        "                data = f.readlines()[0].split(\",\")\n",
        "                all_data[\"Sequence\"].append(data[0])\n",
        "                all_data[\"Wildtype\"].append(data[1].split(\" \")[0])\n",
        "                all_data[\"Mutant\"].append(data[1].split(\" \")[-1])\n",
        "                all_data[\"Score\"].append(float(data[2].replace(\"\\n\",\"\")))\n",
        "        \n",
        "        df = pd.DataFrame.from_dict(all_data)\n",
        "        df.sort_values(\"Score\", ascending=False, inplace=True,ignore_index=True)\n",
        "        \n",
        "        return df.head(10)\n",
        "    \n",
        "    def get_seqs(self, data):\n",
        "        print(data)\n",
        "        # create sequence with the individual mutations\n",
        "        to_mutate = dict(zip(data['Position'], data['Mutant']))\n",
        "        mut_seq = list(self.native)\n",
        "        for i in range(len(self.native)):\n",
        "            if (i+1) in to_mutate:\n",
        "                mut_seq[i] = f\"<{to_mutate[i+1]}>\"\n",
        "        return \"\".join(mut_seq)\n",
        "\n",
        "    def parse_pssm(file_path):\n",
        "      with open(file_path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "      \n",
        "      # Skip the header and find the start of the matrix\n",
        "      start_index = 0\n",
        "      for i, line in enumerate(lines):\n",
        "          if line.strip() and all(c.isalpha() or c.isspace() for c in line.strip()):\n",
        "              start_index = i + 1\n",
        "              break\n",
        "      \n",
        "      # Parse the matrix\n",
        "      pssm = []\n",
        "      for line in lines[start_index:]:\n",
        "          if line.strip():  # Skip empty lines\n",
        "              parts = line.split()\n",
        "              try:\n",
        "                  position = int(parts[0])\n",
        "              except ValueError:\n",
        "                  continue  # Skip lines that don't start with an integer\n",
        "              \n",
        "              residue = parts[1]\n",
        "              scores = [int(x) for x in parts[2:22]]  # Assuming there are 20 amino acids\n",
        "              other_data = parts[22:]  # Capture any additional data at the end of the line\n",
        "              pssm.append({\n",
        "                  'position': position,\n",
        "                  'residue': residue,\n",
        "                  'scores': scores,\n",
        "                  'other_data': other_data\n",
        "              })\n",
        "      \n",
        "      return pssm\n",
        "\n",
        "def filter_positions_with_fewer_negatives(pssm_data, max_negative_scores):\n",
        "    filtered_positions = []\n",
        "    for entry in pssm_data:\n",
        "        negative_count = sum(1 for score in entry['scores'] if score < 0)\n",
        "        if negative_count < max_negative_scores:\n",
        "            filtered_positions.append(entry['position'])\n",
        "    return filtered_positions\n",
        "\n",
        "def print_positions_in_format(positions):\n",
        "    # Helper function to format a list of positions as ranges\n",
        "    def format_as_ranges(positions):\n",
        "        if not positions:\n",
        "            return \"\"\n",
        "        ranges = []\n",
        "        start = positions[0]\n",
        "        end = start\n",
        "        for pos in positions[1:]:\n",
        "            if pos == end + 1:\n",
        "                end = pos\n",
        "            else:\n",
        "                ranges.append(f\"{start}-{end}\" if start != end else f\"{start}\")\n",
        "                start = pos\n",
        "                end = start\n",
        "        ranges.append(f\"{start}-{end}\" if start != end else f\"{start}\")\n",
        "        return \",\".join(ranges)\n",
        "    \n",
        "    formatted_positions = format_as_ranges(positions)\n",
        "    print(f\"Positions to keep fixed in the sequence: {formatted_positions}\")\n",
        "    return formatted_positions\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_run = [\"6ane\"]\n",
        "for example in example_run:\n",
        "    x = evoFilter(example)\n",
        "    alignment = x.run()\n",
        "# Usage\n",
        "pssm_file_path = './temp/pssm.txt'\n",
        "pssm_data = evoFilter.parse_pssm(pssm_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 18  # Set the maximum number of negative scores allowed\n",
        "filtered_positions = filter_positions_with_fewer_negatives(pssm_data, n)\n",
        "print(f\"Fixing {len(filtered_positions)} positions\")\n",
        "formatted_positions = print_positions_in_format(filtered_positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GjdIxO4j-Hnn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title Run ProteinMPNN to design new sequences for given backbone\n",
        "\n",
        "import warnings, os, re\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "os.system(\"mkdir -p output\")\n",
        "\n",
        "# USER OPTIONS\n",
        "#@markdown #### ProteinMPNN options\n",
        "model_name = \"v_48_020\" #@param [\"v_48_002\", \"v_48_010\", \"v_48_020\", \"v_48_030\"]\n",
        "#@markdown #### Input Options\n",
        "pdb='benchmarked/6ane.pdb' #@param {type:\"string\"}\n",
        "#@markdown - leave blank to get an upload prompt\n",
        "chains = \"A\" #@param {type:\"string\"}\n",
        "homooligomer = False #@param {type:\"boolean\"}\n",
        "#@markdown #### Design constraints\n",
        "fix_pos = \"1,4-6,9,12-19,21,23-28,30-33,40-42,44-47,49-52,55-56,59-67,69,71-73,76,81-84,86-89,91,93-94,96-97,99-101,103-121,123-124,126,128-129,131,138-149,151-155,157-168,170-177,179-180,183-186,188,190-198,200,202-208,210-228,230,232-234,236,238,241-242,244,246,248-260,262\" #@param {type:\"string\"}\n",
        "#@markdown - specify which positions to keep fixed in the sequence (example: `1,2-10`)\n",
        "#@markdown - you can also specify chain specific constraints (example: `A1-10,B1-20`)\n",
        "#@markdown - you can also specify to fix entire chain(s) (example: `A`)\n",
        "inverse = False #@param {type:\"boolean\"}\n",
        "#@markdown - inverse the `fix_pos` selection (define position to \"free\" [or design] instead of \"fix\")\n",
        "rm_aa = \"\" #@param {type:\"string\"}\n",
        "#@markdown - specify amino acid(s) to exclude (example: `C,A,T`)\n",
        "\n",
        "#@markdown #### Design Options\n",
        "num_seqs = 32 #@param [\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\"] {type:\"raw\"}\n",
        "sampling_temp = 0.1 #@param [\"0.0001\", \"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "#@markdown - Sampling temperature for amino acids, T=0.0 means taking argmax, T>>1.0 means sample randomly.\n",
        "\n",
        "#@markdown Note: designed sequences are saved to `design.fasta`\n",
        "\n",
        "# cleaning user options\n",
        "chains = re.sub(\"[^A-Za-z]+\",\",\", chains)\n",
        "if fix_pos == \"\": fix_pos = None\n",
        "rm_aa = \",\".join(list(re.sub(\"[^A-Z]+\",\"\",rm_aa.upper())))\n",
        "if rm_aa == \"\": rm_aa = None\n",
        "\n",
        "pdb_path = get_pdb(pdb)\n",
        "if \"mpnn_model\" not in dir():\n",
        "  mpnn_model = mk_mpnn_model(model_name)\n",
        "\n",
        "mpnn_model.prep_inputs(pdb_filename=pdb_path,\n",
        "                       chain=chains, homooligomer=homooligomer,\n",
        "                       fix_pos=fix_pos, inverse=inverse,\n",
        "                       rm_aa=rm_aa, verbose=True)\n",
        "out = mpnn_model.sample(num=num_seqs//32, batch=32,\n",
        "                        temperature=sampling_temp,\n",
        "                        rescore=homooligomer)\n",
        "\n",
        "with open(\"design.fasta\",\"w\") as fasta:\n",
        "  for n in range(num_seqs):\n",
        "    line = f'>score:{out[\"score\"][n]:.3f}_seqid:{out[\"seqid\"][n]:.3f}\\n{out[\"seq\"][n]}'\n",
        "    fasta.write(line+\"\\n\")\n",
        "\n",
        "labels = [\"score\",\"seqid\",\"seq\"]\n",
        "data = [[out[k][n] for k in labels] for n in range(num_seqs)]\n",
        "\n",
        "df = pd.DataFrame(data, columns=labels)\n",
        "df.to_csv('output/mpnn_results.csv')\n",
        "data_table.DataTable(df.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8LtcHb-haU6t"
      },
      "outputs": [],
      "source": [
        "#@title ### Get amino acid probabilities from ProteinMPNN (optional)\n",
        "mode = \"unconditional\" #@param [\"unconditional\", \"conditional\", \"conditional_fix_pos\"]\n",
        "#@markdown - `unconditional` - P(sequence | structure) \n",
        "#@markdown - `conditional` - P(sequence | structure, sequence)\n",
        "#@markdown - `conditional_fix_pos` - P(sequence[not_fixed] | structure, sequence[fix_pos])\n",
        "show = \"all\" \n",
        "import plotly.express as px\n",
        "from scipy.special import softmax\n",
        "from colabdesign.mpnn.model import residue_constants\n",
        "L = sum(mpnn_model._lengths)\n",
        "fix_pos = mpnn_model._inputs.get(\"fix_pos\",[])\n",
        "free_pos = np.delete(np.arange(L),fix_pos)\n",
        "\n",
        "if mode == \"conditional\":\n",
        "  ar_mask = 1-np.eye(L)\n",
        "  logits = mpnn_model.score(ar_mask=ar_mask)[\"logits\"]\n",
        "  pdb_labels = None\n",
        "if mode == \"conditional_fix_pos\":\n",
        "  assert \"fix_pos\" in mpnn_model._inputs, \"no positions fixed\"\n",
        "  ar_mask = 1-np.eye(L)\n",
        "  p = np.delete(np.arange(L),mpnn_model._inputs[\"fix_pos\"])\n",
        "  ar_mask[free_pos[:,None],free_pos[None,:]] = 0\n",
        "  logits = mpnn_model.score(ar_mask=ar_mask)[\"logits\"]\n",
        "  logits = logits[free_pos]\n",
        "  pdb_labels = np.array([f\"{i}_{c}\" for c,i in zip(mpnn_model.pdb[\"idx\"][\"chain\"], mpnn_model.pdb[\"idx\"][\"residue\"])])\n",
        "  pdb_labels = pdb_labels[free_pos]\n",
        "else:\n",
        "  ar_mask = np.zeros((L,L))\n",
        "  logits = mpnn_model.score(ar_mask=ar_mask)[\"logits\"]\n",
        "  pdb_labels = None\n",
        "\n",
        "pssm = softmax(logits,-1)\n",
        "np.savetxt(\"output/pssm.txt\",pssm)\n",
        "\n",
        "fig = px.imshow(np.array(pssm).T,\n",
        "               labels=dict(x=\"positions\", y=\"amino acids\", color=\"probability\"),\n",
        "               y=residue_constants.restypes + [\"X\"],\n",
        "               x=pdb_labels,\n",
        "               zmin=0,\n",
        "               zmax=1,\n",
        "               template=\"simple_white\",\n",
        "              )\n",
        "fig.update_xaxes(side=\"top\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U_YRqlMraLNl"
      },
      "outputs": [],
      "source": [
        "#@title Run AlphaFold Prediction on ProteinMPNN sequences (optional)\n",
        "#@markdown ###AlphaFold Options\n",
        "num_models = 1 #@param [\"1\",\"2\",\"3\",\"4\",\"5\"] {type:\"raw\"}\n",
        "num_recycles = 1 #@param [\"0\",\"1\",\"2\",\"3\"] {type:\"raw\"}\n",
        "use_multimer = False #@param {type:\"boolean\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "rm_template_interchain = False #@param {type:\"boolean\"}\n",
        "if not os.path.isdir(\"params\"):\n",
        "  os.system(\"mkdir params\")\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(\"aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar\")\n",
        "  os.system(\"tar -xf alphafold_params_2022-12-06.tar -C params\")\n",
        "\n",
        "# where pdb files will be save:\n",
        "if not os.path.isdir(\"output/all_pdb\"):\n",
        "  os.system(\"mkdir output/all_pdb\")\n",
        "else:\n",
        "  os.system(\"rm output/all_pdb/*\")\n",
        "\n",
        "from colabdesign.af import mk_af_model\n",
        "af_args = [pdb_path, chains, homooligomer,\n",
        "           use_multimer, use_templates]\n",
        "if \"af_arg_current\" not in dir() or af_args != af_arg_current:\n",
        "  af_model = mk_af_model(use_multimer=use_multimer,\n",
        "                         use_templates=use_templates,\n",
        "                         best_metric=\"dgram_cce\")\n",
        "  af_model.prep_inputs(pdb_path,chains,homooligomer=homooligomer)\n",
        "  af_arg_current = [x for x in af_args]\n",
        "\n",
        "af_model.restart()\n",
        "af_model.set_opt(\"template\", rm_ic=rm_template_interchain)\n",
        "\n",
        "with tqdm.notebook.tqdm(total=out[\"S\"].shape[0], bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "  for n,S in enumerate(out[\"S\"]):\n",
        "    seq = S[:af_model._len].argmax(-1)\n",
        "    af_model.predict(seq=seq,\n",
        "                    num_recycles=num_recycles,\n",
        "                    num_models=num_models,\n",
        "                    verbose=False)\n",
        "    (rmsd, ptm, plddt) = (af_model.aux[\"log\"][k] for k in [\"rmsd\",\"ptm\",\"plddt\"])\n",
        "    af_model.aux[\"log\"][\"composite\"] = ptm * plddt\n",
        "    af_model._save_results(save_best=True, verbose=False)\n",
        "    af_model.save_current_pdb(f\"output/all_pdb/n{n}.pdb\")\n",
        "    af_model._k += 1\n",
        "    pbar.update(1)\n",
        "\n",
        "af_model.save_pdb(f\"output/best.pdb\")\n",
        "\n",
        "data = []\n",
        "labels = [\"dgram_cce\",\"plddt\",\"ptm\",\"i_ptm\",\"rmsd\",\"composite\",\"mpnn\",\"seqid\",\"seq\"]\n",
        "for n,af in enumerate(af_model._tmp[\"log\"]):\n",
        "  data.append([af[\"dgram_cce\"],\n",
        "               af[\"plddt\"],\n",
        "               af[\"ptm\"],\n",
        "               af[\"i_ptm\"],\n",
        "               af[\"rmsd\"],\n",
        "               af[\"composite\"],\n",
        "               out[\"score\"][n],\n",
        "               out[\"seqid\"][n],\n",
        "               out[\"seq\"][n]])\n",
        "\n",
        "df = pd.DataFrame(data, columns=labels)\n",
        "df.to_csv('output/alphafold_results.csv')\n",
        "data_table.DataTable(df.sort_values(\"dgram_cce\").round(3))\n",
        "#@markdown Note: designed pdbs are saved to `output/all_pdb/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZOtuzwwUAgHj"
      },
      "outputs": [],
      "source": [
        "#@title download predictions (optional)\n",
        "from google.colab import files\n",
        "os.system(f\"zip -r output.zip output/\")\n",
        "files.download(f'output.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OdS7x6MmPpvl"
      },
      "outputs": [],
      "source": [
        "#@title display protein (optional) {run: \"auto\"}\n",
        "show_best = True #@param {type:\"boolean\"}\n",
        "show_idx = 0 #@param {type:\"integer\"}\n",
        "#@markdown - Enter index of protein to show, if `show_best` is disabled.\n",
        "#@markdown - Note: these are NOT sorted and correspond to \n",
        "#@markdown the index in pandas dataframe above.\n",
        "color = \"pLDDT\" #@param [\"chain\", \"pLDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "color_HP = False #@param {type:\"boolean\"}\n",
        "animate = True #@param {type:\"boolean\"}\n",
        "#@markdown - if `num_models` > 1, will iterate through the models when `animate` is enabled.\n",
        "if not show_best:\n",
        "  pdb_str = pdb_to_string(f\"output/all_pdb/n{show_idx}.pdb\")\n",
        "else:\n",
        "  pdb_str = None\n",
        "af_model.plot_pdb(show_sidechains=show_sidechains,\n",
        "                  show_mainchains=show_mainchains,\n",
        "                  color=color, color_HP=color_HP,\n",
        "                  animate=animate, pdb_str=pdb_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74LAQHZGTZCH"
      },
      "outputs": [],
      "source": [
        "#@title animate (optional)\n",
        "#@markdown Note: animation frames are sorted worst to best design\n",
        "def sort_traj(self, metric=\"dgram_cce\"):\n",
        "  if metric in [\"plddt\",\"ptm\",\"i_ptm\",\"seqid\",\"composite\"]:\n",
        "    metric_higher_better = True\n",
        "  else:\n",
        "    metric_higher_better = False\n",
        "  num = len(self._tmp[\"traj\"][\"seq\"])\n",
        "  log = self._tmp[\"log\"][-num:]\n",
        "  if metric in log[0]:\n",
        "    n = np.array([x[metric] for x in log]).argsort()\n",
        "    if metric_higher_better: n = n[::-1]\n",
        "    sub_traj = {k:[v[m] for m in n] for k,v in self._tmp[\"traj\"].items()}\n",
        "    return sub_traj\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "sub_traj= sort_traj(af_model)\n",
        "\n",
        "color_by = \"plddt\" #@param [\"chain\", \"plddt\", \"rainbow\"]\n",
        "dpi = 100 #@param {type:\"integer\"}\n",
        "HTML(af_model.animate(traj={k:v[::-1] for k,v in sub_traj.items()}, color_by=color_by, dpi=dpi))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
